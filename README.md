# autogpt是如何工作的

autogpt是prompt工程的结晶，它把你的需求，通过prompt工程进行包装，然后发送给chatgpt。下面我们来看看，autogpt实际发送了什么给chatgpt，chatgpt又是如何反馈的。

下面开始分析这些prompt和它们的返回结果，每一条分析对应的文件都存在这个repo中，举例来说，下面第一条分析对应的prompt存储在[prompts/1.txt](prompts/1.txt)中，而chatgpt的返回结果存储在[responses/1.txt](responses/1.txt)中。

根据prompt中的信息互相之间的继承关系，我会把它们称为主线或支线。

1. 首先，我们给出的任务是“写一篇关于冰箱如何发明的论文”。
   autogpt将其包装为prompt。注意这里都是开发者根据prompt经验手写的静态prompt，而不是AI生成的。
   AI的返回结果生成了角色名和目标。
2. 这些chatgpt生成的角色名和目标，又被autogpt融入到prompt中，开始进入正式的思考循环。这里是主线。
   注意此处包含了一个非常复杂的prompt工程，它会在整个主线中被使用。
   chatgpt的返回结果要求进行google查询。
3. 第三条prompt看起来和上下文没有什么关系，它的返回结果也是没有实际用处的。
   但是下面同类型的prompt会很多，因为这个支线的作用大约是对历史对话进行概括，所以我们把这个对话支线称为概括支线。
4. 第四条prompt是接续第二条的主线，执行第二条prompt中chatgpt发起的命令，返回执行结果给chatgpt。不过本次执行google搜索恰好是失败的。
   而chatgpt在失败的基础上，选择执行访问wiki的命令
5. 第五条prompt，大概是我在上一条google搜索失败后，手动选择进行反思所产生的，它是独立的支线，它几乎没有提及上下文的细节，但是重审了一遍chatgpt陈述的目的，我猜测它也是由开发者根据prompt工程经验，手动写的。
   而chatgpt对此的反馈，算是重新梳理计划。
6. 这一条，和第3条属于同类，是概括支线，其中暂时还没有有价值的信息
7. 这是接续第4条失败后的主线，它把第5条支线中产生的反思反馈嫁接了过来。
   chatgpt对此的反馈，是再次执行google搜索。
8. 这里还是概括支线，我们看到autogpt把之前chatgpt选择执行的命令和它们的执行结果放了进来。
   而chatgpt因而对其进行了概括。暂且不知道这个概括的结果会被如何使用。
9. 接续第7条的主线，autogpt在完成google搜索后，把结果发送给chatgpt。
   需要注意的是，这一条中对主线的历史聊天记录进行了裁剪，或许第8条概括的文本因此可以在这里起作用了？
   chatgpt对此的想法是应该保存下这些结果，但是选择的命令却是无厘头的要读取一个文件，而我知道这个文件此刻是不存在的。
10. 又是概括支线，其中我们可以看到，它使用了第8条中chatgpt概括的结果，然后把第9条中执行的搜索命令放了进来，但是搜索结果没有放进来。
11. 接续第9条的主线，同时继续裁剪。autogpt执行了那个不存在的文件的读取命令，理所当然的出错了。
    chatgpt的反应是把一些内容写入同名文件中。我对比检查确认，这些内容来自google搜索的第一条。一字没变。
12. 接续第10条的概括支线，这里添加了第9条搜索获得的全部（大概10条？）搜索结果。
    然后chatgpt依然把它们归纳成了一个短小的文本。
13. 接续第11条，继续裁剪，尤其是第9条的搜索结果被裁剪掉了。autogpt报告chatgpt，文件保存成功了。
    chatgpt要求继续读这个文件
14. 接续12条继续概括，但是没有需要概括的新内容
15. 接续13条，似乎没有裁剪，返回文件读取的结果。
    chatgpt对此的反应是要写一些新内容到一个新文件中。它想要写的内容是timeline，是关于人名，时间和日期的，其实第9条的搜索中有类似的内容存在，但是到这里的时候，这部份内容已经被第13条裁剪掉了。此时chatgpt似乎开始根据从自己的知识库中抽取信息，把这些内容写出来了。
    通过google搜索得到内容被丢弃了，而从自己的黑箱中挖出了它相信是正确的历史记录。
16. 接续14条的概括支线，但是没有新内容
17. 接续15条的主线，保存文件。
    然后chatgpt要求再次读取这个文件。
18. 接续16条的概括支线，但是没有新内容
19. 接续17条的主线，读取文件。
    然后chatgpt又想要继续写文件了，它是来灵感了吗？
20. 接续18的概括支线，添加了第11条的文件读写操作。
    到这里我算是理解了。这里autogpt会添加的内容， 正是马上要被从主线中裁剪掉的对话记录。
    那么之后的概括支线，就可以不用看了，原理就是这么简单了。
21. 接续19条的主线，保存文件成功。
    按照之前的规律，我觉得chatgpt又要把保存的文件读出来看看了。但是它并没有，而是又想出了一些新的内容，想要保存下来。看来它现在有很好的灵感。
22. 接续20的概括支线。
23. 接续21的主线，保存成功。
    然后chatgpt写了一段python代码，大致要读取之前保存的timeline.txt做些什么。
    但是对于这些python代码，它首先要求进行代码分析。
24. 是一个独立的对话支线，就是进行代码分析的。
    但是，看来代码分析被autogpt的开发者设计为需要调用gpt4进行的任务。原因可能是因为让autogpt全自动执行python代码是不允许任何差错的，或者说差错越小越好。
    但是我的帐号不支持gpt4，所以这里只会得到一个调用错误。
25. 接续22的概括支线
26. 接续23的主线，把24产生的错误报告给了chatgpt。不是一个很严谨的报告，autogpt完全没对gpt4权限不足这种情况进行处理。
    chatgpt对此的反应，是把代码分析命令替换成了代码改进。
27. 代码改进的独立支线，和代码分析的情况几乎一样，依然被设计为要求gpt4，依然失败了
28. 接续25的概括支线
29. 接续26的主线，继续报告27产生的错误。
    chatgpt的反应似乎是，那么就不要用python了，直接继续写文本，然后要求保存。
30. 接续28的概括支线
31. 接续29，保存成功
    到此为止，chatgpt的灵感或许用完了，它要求进行google搜索

那么到31条为止，这次执行就被我中止了。
    
    
   

